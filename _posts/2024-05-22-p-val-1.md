---
title: "통계적 가설검정의 개념: Fisher vs. Neyman-Pearson"
tags: [statistics]
categories: blog
cover: /files/cover/2024-05-22-p-val-1.png
---
아래의 내용은 Daniël Lakens의 「[Improving Your Statistical Inferences](https://lakens.github.io/statistical_inferences/)」와 Aris Spanos의 「Probability Theory and Statistical Inference」를 바탕으로 여러 문헌을 공부하며 정리한 내용입니다.

- 제가 통계학 전공자가 아니라는 점을 기억하시고, 이 글에 통계학적으로 잘못된 서술이 있을 수 있다는 점을 유념하여 비판적으로 읽어주길 바라요. 오류를 발견하면 언제든 이야기해주세요.
- 글의 내용을 다른 곳에 인용하실 때에는 이 **글의 출처와 함께 원문의 서지 정보를 필히 밝혀**주세요.  특히 **1-1, 1-2, 1-3절**의 내용을 인용할 때는 **Spanos (2003)의 서지정보를 명시**하도록 하고, 기타 **in-text citation이 명시된 항목**의 경우에도 **해당 서지정보를 함께 밝혀**주길 바랍니다. 연구, 아이디어, 주장 등은 한 사람이 뚝딱 생각하여 만드는 것이 아니라 선행 문헌들 위에서 발전되어 온 것들입니다 (a.k.a. 거인의 어깨). 원 문헌을 저술한 저자를 명시하여 그들이 받아 마땅한 공을 밝히도록 합시다.

**Null Statistical Hypothesis Testing** 정리하기 (1/4)

[1장. 통계적 가설검정의 개념: Fisher vs. Neyman-Pearson]({% post_url 2024-05-22-p-val-1 %}) **←**

[2장. p-value의 특징]({% post_url 2024-05-23-p-val-2 %})

[3장. p-value를 제대로 보고하기]({% post_url 2024-05-28-p-val-3 %})

[4장. p-value와 error rate에 대한 오해와 물음]({% post_url 2024-05-29-p-val-4 %})



## 1-1. Fisher's Test of Significance

### 개념과 과정

 Ronald Fisher가 내놓은 Test of Significance는 다음과 같이 진행된다[^1]. 

1. **Null hypothesis $\mathbf{H_0}$를 정한다**. 이때 $H_0: \theta = \theta_0$의 형태를 가진다.

	- $H_0$는 효과가 없다고(null) 가정했을 때의 가설을 말한다.
	- 하지만 모든 $H_0$가 효과가 없다는 가설일 필요는 없다. $\mu_1 - \mu_2 = 0$과 같이 효과가 없는 경우일 수도 있지만, $\mu_1 - \mu_2 = 6$이나 $r = 0.4$와 같이 특정한 값을 취할 수도 있다. Null hypothesis라는 용어가 효과없음을 가정하는 가설만을 의미한다고 오해될 수 있어서 **target hypothesis**와 같이 더 포괄적인 용어가 사용되기도 한다 (Greenland, 2023).
	- 중요한 것은 **$\mathbf{H_0}$가 sampling distribution에 관한 정보를 담고 있어야** 한다는 점이다. 다시 말해 $H_0$는 test statistic $\tau(\mathbf{X})$의 sampling distribution을 특정할 수 있는 조건을 기술한다. 이는 $H_0$가 참이라는 전제 하에 정해진 sampling distribution 내지 null model을 우리가 관찰하여 얻은 test statistic과 비교하기 위함이다. 둘을 비교하여 $H_0$가 참일 때 관측된 statistic이 얼마나 드문지 알 수 있다. 

2. 목적에 맞는 **test statistics를 정한다**.

	 - 이때 *test statistic* $\tau(\mathbf{X})$는 $H_0:\theta = \theta_0$가 맞다는 가정 하에 그 distribution이 알려져 있어야 하고, 이 distribution은 다른 미지의 parameter에 의존적이지 않아야 한다.

3. **$\textbf{p}$-value를 계산한다**. 이때 $p$-value는 statistic $\tau(\mathbf{X})$의 관측값인 $\tau(\mathbf{x})$의 tail-area probability로 계산된다.

	- 즉 $p\text{-value} = P(\tau(\mathbf{X}) \ge \tau(\mathbf{x})\mid H_0)$ 로서, sampling distribution에서 test statistic의 관측값과 그 이상의 극단적인 값이 관측될 이론적 확률을 의미한다.

4. **$\mathbf{p}$-value를 해석한다**. 

	- $p$-value가 작다면 (1) test statistic이 관측된 상황이 매우 드문 event이거나, (2) 가설로 상정된 null hypothesis가 타당하지 않은 가설이거나의[^3] 두 경우로 해석될 수 있다[^2].
	- 현실적으로 연구자는 (1)보다는 (2)의 관점을 택하여 **$p$-value를 null hypothesis가 믿을만한지에 관한 척도로** 사용할 수 있다.  $p$-value는 작으면 작을수록 $\tau(\mathbf{x})$가 $H_0$ 하에서 관측될 법하지 않기 때문에 $H_0$를 믿지 않을 이유가 더 커지는 것으로 이해된다. 
	- **통계적 관점**에서 Fisher의 방법을 통해 알 수 있는 것은 **$H_0$ 하에서 연구 결과가 나타날 확률**이다. 그러므로 Fisher의 $p$-value는 $H_0$를 잘못된 것으로 기각하거나 $H_0$에 반대되는 가설을 지지하는 **의사결정에 관한 척도가 아니다**. 
	- $p$-value가 작은 값인지 아닌지에 관해서 Fisher는 초기 저작과 후기 저작에서 의견을 달리한다.

		- 초기에 Fisher는 significance level을 관습적으로 5%로 제시하며 유의하지 않은 결과는 무시되어야한다고 본다 (Fisher, 1935, p.13, 재인용:Gigerenzer et al., 2004).
		- **Fisher는 이후** $p$-value가 얼마나 작아야하는가에 관해서는 **연구마다, 연구자마다 다를 수 있다**고 하며 $p$-value의 값을 **그대로 보고하여** 동료 연구자와 공유해야한다고 본다 (Fisher, 1956, p. 42, 재인용: Gigerenzer et al., 2004).

### 목적

- Fisher's test of significance를 통해 얻은 $p$-value는 **observed statistic과 그 이상의 극단값이 null model 하에서 나올 확률**로서, 검정하고자 하는 **null hypothesis가 얼마나 믿을만한지에 대한 정립된 척도**를 제공한다 (Fisher, 1956, p. 44). $p$-value는 작으면 작을수록 $\tau(\mathbf{x})$가 $H_0$ 하에서 관측될 법하지 않기 때문에 $H_0$를 받아들이지 않을 이유가 더 커지는 것으로 이해된다. 

## 1-2. Neyman-Pearson's Statistical Hypothesis Testing

Jerzy Neyman과 Egon Pearson[^4]은 $p$-value에 대한 Gosset과 Fisher의 연구를 바탕으로 **statistical hypothesis testing**이라는 방법을 개발한다. Fisher의 test of significance와는 달리 대립가설 (alternative hypothesis; $H_a$)이 설정되고, 연구자는 잠정적으로 두 가설 중 하나가 참인 것처럼 받아들이게 된다.

### 개념과 과정

Neyman–Pearson의 statistical hypothesis testing은 다음과 같이 진행된다 (Spanos, 2003, 14.3절).

1. **Null hypothesis $H_0$와 alternative hypothesis $H_1$를 정한다**.

	- 각각 $H_0: \theta = \theta_0$ 와 $H_1: \theta \ne \theta_0$의 형태를 가진다. 
	- 이때 parameter space $\Theta$는 상호배타적인(mutually exclusive) 두 부분집합으로 분할된다:

		$$\Theta_0 := \{\theta_0\}\text{ and }\Theta_1 := \Theta -\{\theta_0\},\quad \text{where } \Theta_0\cap\Theta_1 = \varnothing, \Theta_0\cup \Theta_1 = \Theta$$

	- 더 일반적인 Neyman-Pearson hypothesis의 형태는 다음과 같다:

		$$H_0: \theta \in \Theta_0 \text{ against }H_1: \theta \in \Theta_1:=\Theta -\Theta_0 $$

	- 이는 사실상 postulated probability model $\Phi = \{f(x;\theta), \theta\in\Theta, x\in \mathbb{R}_X\}$을 양분한다:

		$$\Phi_0 = \{f(x;\theta), \theta\in\Theta_0, x\in \mathbb{R}_X\}, \Phi_1 = \{f(x;\theta), \theta\in\Theta_1, x\in \mathbb{R}_X\}$$

		$H_0$와 $H_1$이 궁극적으로는 parameter에 관한 가설이라기보다 *distribution*에 관한 가설이라는 점을 알 수 있다.

		$$H_0:f(x)\in \Phi_0\text{ against }H_1:f(x)\in\Phi_1 $$

2. **Rejection region**을 정한다.

	- Neyman–Pearson test의 주 목적은 $H_0$를 **수용하거나 기각하기 위한 결정 규칙** (decision rule)을 만드는 것이다. 이 결정은 test statistic $\tau(\mathbf{X})$를 기준으로 하므로, $\tau(\mathbf{X})$는 sample space $\mathcal{C}$를 두 집합 $C_0$와 $C_1$로 분할하게 된다.
	- $C_0:=\lbrace\mathbf{x}:\tau(\mathbf{x}) \le c_\alpha\rbrace$의 형태를 가지며 acceptance region이라 불리고, $C_1:=\lbrace\mathbf{x}:\tau(\mathbf{x}) > c_\alpha\rbrace$의 형태를 가지며 rejection region이라 불린다.
	- 각각 	$C_0 \cup C_1 = \mathcal{C}$ and $C_0 \cap C_1 = \varnothing$ 을 만족한다.
	- $H_0$를 수용할지 기각할지에 관한 결정은 두 region의 측면에서 정해진다:

		$$\text{(i) if } \mathbf{x}\in C_0:\text{accept }H_0,\quad \text{(ii) if } \mathbf{x}\in C_1:\text{reject } H_0$$

3. **Type I error와 type Ⅱ error**

	1. 두 종류의 error가 있다.
		- **type I error**: Null hypothesis가 타당한데(valid) 이를 기각하는 오류
		- **type Ⅱ error**: Null hypothesis가 타당하지 않은데(not valid) 이를 수용하는 오류

	2. **Probability of type I error**

		$\theta_0 = \theta$ 일 때 type I error를 저지를 확률은 다음의 일반적인 형태로 표현될 수 있다:

		$$P(\mathbf{x} \in C_1; \theta = \theta_0) = \alpha$$

		- $\alpha$는 long-run type I error로서, 연구자가 최대로 허용할 수 있는 type I error probability를 의미한다[^5]. 
		- Rejection region이 넓을 수록 $\alpha$는 줄어들지만, 이는 type II error의 확률을 증가시키게 된다.

	3. **Probability of type Ⅱ error**

		$\theta = \theta_1$일 때 type II error를 저지를 확률은 다음의 일반적인 형태로 표현될 수 있다:

		$$P(\mathbf{x}\in C_0; \theta = \theta_1) = \beta(\theta_1) $$

		- 이때 test statistic의 distribution을 알아야 확률을 계산할 수 있는데, $\Theta_1:=\Theta -\Theta_0$  의 값을 특정해야 distribution을 알 수 있다. 위의 식에서 $\beta(\theta_1)$은 $\beta$가 $\theta_1$에 의해 결정된다는 의미라는 것을 이해할 수 있다.
		- $\alpha$와는 달리, $\beta$는 rejection region이 넓을 수록 증가한다.
		- $\alpha$가 커지면 $\beta$가 줄어들고, $\beta$가 커지면 $\alpha$가 줄어다는 사실을 내가 만든 다음 그림을 통해 이해할 수 있겠다.

		<p align="left">
  			<img src="/files/img/alpha_beta.svg" width="60%">
		</p>

4. **최적의 test 정하기**

	1. Neyman–Pearson은 $H_0$를 $H_1$보다 더 중요하게 다룬다. 즉 낮은 $\alpha$를 먼저 정하고, 이후에 $\beta$를 최소화하는 방향으로 test를 선택한다는 의미이다. 가령 연구자는 $\alpha  = 0.01$로 정해두고 이후 $\beta$를 최소화하는 test를 선택하게 된다. 
	2. 일반화하면 다음과 같다. $|\tau(\mathbf{X})| > c_\alpha$일 때 $H_0$를 기각한다면,  $\tau(\mathbf{X})$는 다음을 만족하도록 선택한다:		
		$$\begin{align}&\text{(a)}\quad P(|\tau(\mathbf{X})| > c_\alpha; H_0\text{ valid}) = \alpha\\
			&\text{(b)}\quad P(|\tau(\mathbf{X})| \le c_\alpha; H_1(\theta)\text{ valid}) = \beta (\theta)\text{ for }\theta \in \Theta_1 \text{ is minimized.}
			\end{align}  $$
	3. 이는 test의 power를 고려하는 측면에서 이해될 수도 있다.

		- **Power of a test**: 타당하지 않은 $H_0$를 기각할 확률로서, 어떤 값 $\theta_1 \in \Theta_1$에 대해 다음과 같이 쓸 수 있다:	
		
			$$P(\theta_1) = P(\mathbf{x}\in C_1;H_1\text{ valid}) $$ ($H_1: \theta \ne \theta_0$에 대해 $\theta$가 가질 수 있는 값이 여럿이므로 이를 함수로 표현한 것이다.)

		- 다시 말해, test의 power는 $H_1$이 타당할 때 $H_0$를 기각할 확률, 또는 family $\Phi_1 = \{f(x;\theta), \theta \in \Theta_1, x\in \mathbb{R}_X\}$에 실제 분포가 속할 확률을 의미한다. 
		- 전체 parameter space $\Theta$에서 정의한 **power function**은 다음과 같다: 

			$$ P_{n}(\theta) = P(\mathbf{x}\in C_1)\text{ for }\theta \in \Theta$$

		- 가설 $H_0: \theta = \theta_0$에 대해 significance level은 power function을 통해 정의될 수 있다:
			$$P_n(\theta_0) = \alpha$$

		- 만약 $\theta_0 \in \Theta_0$이고 $\Theta_0$가 한 개 이상의 원소를 가진다면, test의 **size**를 다음과 같이 정의한다:
		
			$$\text{size of the test} =\alpha = \max_{\theta\in\Theta_0}P_n(\theta) $$ 
			
		그러므로 test의 size $\alpha$는 $\Theta_0$의 임의의 원소 $\theta_0$에 대해 $H_0$를 잘못 기각할 최대 확률을 의미한다.
		- 가장 적절한 test는 $\alpha$가 정해진 이후, 모든 $\theta \in \Theta_1$에 대해 power를 최대로 하는 test이다.
 
	4. Test statistic $\tau(\mathbf{X})$를 선택했다면 $H_0$ 하에서의 distribution을 통해 $\lvert\tau(\mathbf{X})\rvert$가 "0으로부터 유의하게 차이나"도록[^6] 하는 $c_\alpha$를 얻을 수 있다. 다음 식을 만족하는 $c_\alpha$를 구하게 된다:

		$$P(|\tau(\mathbf{X})| > c_\alpha;H_0\text{ valid}) = \alpha$$

		이런 이유로 $\alpha$는 **significance level** (유의 수준)이라고도 불린다. 
	5. e.g. $\sigma^2$를 모르는 상황에서 $H_0: \mu = \mu_0$와 $H_1: \mu \ne \mu_0$를 test하려 한다 (Two-sided test). 
		- Test statistic은 $\tau(\mathbf{X}):=\frac{\hat{\mu_n} - \mu_0}{s/\sqrt{n}} \sim St(n-1)$
		- Rejection region은 $C_1 = \lbrace\mathbf{x}: \lvert\tau(\mathbf{x})\rvert > c_\alpha \rbrace$
		- $c_\alpha$는 $\int_{c_\alpha}^\infty \phi(z)dz = \frac{1}{2}\alpha$ where $\phi(z)$ is Student's $t$ density (pdf).

5. **$H_0$와 $H_1$중 하나를 택한다**
	- Acceptance region $C_0:=\lbrace\mathbf{x}:\tau(\mathbf{x}) \le c_\alpha\rbrace$ 에 대해 $\mathbf{x} \in C_0$일 때 $H_0$를 수용하고[^7], rejection region $C_1:=\lbrace\mathbf{x}:\tau(\mathbf{x}) > c_\alpha\rbrace$에 대해 $\mathbf{x}\in C_1$일 때 $H_0$를 기각한다.
	- Neyman–Pearson에서 $p$-value 자체를 핵심 개념으로 사용하지는 않으나, 사실상 test statistic $\tau(\mathbf{x})$가  acceptance region 혹은 rejection region에 포함되는지는 $p$-value와 $\alpha$를 비교하여도 알 수 있다. 그러므로  $p < \alpha$일 때 $H_0$를 기각하고, $p \ge \alpha$일 때 $H_0$를 수용한다. 단, $p$-value를 소위 'observed type I error rate' 등으로 이해하는 것은 잘못되었는데, 이에 관한 내용은 추후 다루겠다.
	
### 목적
Neyman과 Pearson은 Fisher의 significance test를 다음 두 가지 이유에서 비판한다 (Spanos, 2003).
- Fisher는 test statistic을 선택하는 기준을 제공하지 않는다. 각각의 $H_0$에 대해 여러 test statistic을 사용할 수 있는데, Fisher는 어떤 것이 가장 적절한 test statistic인지에 관한 방법을 설명하지 않는다.
- $p$-value를 $H_0$에 대한 믿음의 척도 (measure of credence)로 사용하는 것은 논리적 근거가 없다. 

이에 대한 해결책으로 Neyman과 Pearson은 **hypothesis testing을 경쟁하는 가설 중 하나를 선택하는 것**으로 본다[^8].

## 1-3.  Neyman–Pearson과 Fisher의 차이
1. Test의 **목적**이 다르다. 그래서 $\alpha$와 $p$-value는 그 성격이 다르다. (Spanos, 2003, 14.5.1절)
	- Neyman–Pearson의 $\alpha$는 **의사결정(decision-making)이라는 행동**의 규칙이 되는 기준값이다. 이때 $\alpha$는 significance level로서, test statistic이 $\alpha$보다  큰지 작은지에 따라 $H_0$를 수용하거나 기각하는 의사결정을 내린다[^9]. 
	- 반면 Fisher의 $p$-value는 결정을 내리기 위한 기준이 아니라 sample data가 $H_0$를 얼마나 믿을만한 것으로 만드는지 **추정하기(inferential) 위한 척도**일뿐이다. 그러므로  Fisher는 $p$-value를 통해 그 이상의 주장을 할 수 없다고 본다.
2. Test의 **범위**가 다르다 (Spanos, 2003, 14.5.2절).
	- Neyman–Pearson의 가설은 $H_0: \theta \in \Theta_0 \text{ against }H_1: \theta \in \Theta_1:=\Theta -\Theta_0$ 의 형태를 가진다. 그래서 parameter space $\Theta$가 $\Theta_0$와 $\Theta_1$으로 분할되며 probability model $\Phi = \{f(x;\theta), \theta \in \Theta, x \in \mathbb{R}_X\}$는 $\Phi_0 = \{f(x;\theta), \theta\in\Theta_0, x\in \mathbb{R}_X\}$와 $\Phi_1 = \{f(x;\theta), \theta\in\Theta_1, x\in \mathbb{R}_X\}$로 분할되는 것이다. 이제 Neyman–Pearson의 가설은 다음과 같이 이해될 수 있다:
	
		$$H_0:f(x)\in \Phi_0\text{ against }H_1:f(x)\in\Phi_1 $$

	- 반면 Fisher의 가설은 다음과 같이 이해된다: 
	
		$$H_0: f(x)\in \Phi_0\text{ against } H_1: f(x)\in [\mathcal{P}-\Phi_0] $$
		이때 $\mathcal{P}$는 *모든*  가능한 statistical model의 집합이다. Fisher는 alternative hypothesis 개념을 거부하긴 했지만, 그의 test에 암묵적인(implicit) alternative hypothesis가 있다는 사실을 부정하지는 못한다[^10]. 
	- Fisher의 implicit alternative hypothesis는 N–P test의 alternative hypothesis보다 범위가 넓다. 
		- 이는 강점이 될 수 있다. 연구자는 '참인' statistical model이 null hypothesis와 (implicit) alternative hypothesis의 합집합 안에 존재한다고 확신할 수 있기 때문이다: 

			$$f(x) \in \mathcal{P} = \Phi_0 \cup [\mathcal{P}-\Phi_0] $$

			반면 N–P test에서는 '참인' statistical model이 null과 alternative 어디에도 존재하지 않을 수 있다는 점에서 그런 확신을 할 수 없다.
		- 이는 약점이 될 수도 있다.  집합 $[\mathcal{P-\Phi_0}]$는 달리 규정된 바가 없는 모든 가능한 모델의 집합이기 때문에 그만큼 다루기 어려울 수 있다. 반면 Neyman–Pearson의 $\Phi_1$은 power function의 측면에서 비교적 다루기 쉬울 수 있다[^11].
3. **Significance level**을 바라보는 관점이 다르다.
	- Neyman과 Pearson은 임의의 특정한 시행에서 error가 발생했는지 알 수 없으므로 **long-run probability**에 초점을 두어야 한다고 본다 (Perezgonzalez. 2015). 여기서 long-run probability란 특정한 statistical experiment를 셀 수 없이 많이 반복하여 계산된 확률, 즉  **relative frequency (상대빈도)** 로서의 확률을 의미한다 (Spanos, 2003, p. 698). 
		- 그러므로 type I error rate ($\alpha$)이 $0.05$라는 말은, statistical experiment를 매우 많이 반복 시행하여 수행한 test 결과의 $5\%$가 type I error라는 의미이다. 가령 $10,000$번의 동일한 시행으로 sample을 얻었다고 하자. $\alpha = 0.05$는 각각의 시행에 대한 $10,000$개의 검정 결과 중 $500$번의 검정 결과에서 type I error가 발생할 수 있다는 의미이다. 
		- $\alpha$는 사전에 (*a priori*) 설정되어야 하는 값이다. 
	- 이와 달리 Fisher의 접근은 **특정한 가설의 특정 연구 결과를 검정하고자** 하는 것이므로 long-run probability를 중요하게 보지 않는다. 
		- Fisher는 관습적으로 사용하던 significance level의 사용을 반대하고, 그것을 long-run probability $\alpha$ 로 해석하는 것 또한 비과학적인 (unscientific) 것으로 여겨 반대한다  (Fisher, 1956, p. 42, 재인용: Gigerenzer et al., 2004). 산업계의 quality-control과는 다르게, 연구자는 동일한 실험을 셀 수 없이 여러번 반복하지 않기 때문이다. 
		- 이러한 측면에서 Fisher는 Neyman과 Pearson이 주장하듯 significance level을 long-run type I error rate으로 해석하는 것은 옳지 않다고 본다. 대신 그는 연구를 출판할 때 exact level of significance (e.g. $p < 0.05$ (x) $p = 0.02$ (o))를 명시하여 동료 연구자와 공유해야 한다고 본다.
		- Fisher의 $p$-value는 사후에 조정될 수 있다. 개별 연구에서 $p$-value를 사후에 (*a posteriori*) 조정할 때 (e.g. Bonferroni correction) error의 영향이 효과적으로 통제될 수 있기 때문이다[^12] (Perezgonzalez, 2015).
4. Null hypothesis statistical testing (NHST; 영가설 통계검정)에 이르러서는 Fisher의 signifance test와 Neyman–Pearson의 statistical hypothesis testing의 요소들이 서로 뭉쳐서 다루어지게 되는 듯하다. Test마다 해석되는 방식은 제각각인 것 같은데, 적어도 Fisherian test와 같이 통계적 유의성이라는 개념이 사용되고, N–P test와 같이 $H_0$와 $H_a$중 하나를 선택하는 결정을 내린다는 점은 공통적인 것 같다.

Fisher의 test와 Neyman–Pearson의 test의 차이에 관해서는 Perezgonzalez (2015)의 리뷰, Berger (2003)의 글, Morimoto (2021)의 글을 보라.

## Reference

- Berger, J. O., & Delampady, M. (1987). Testing Precise Hypotheses. *Statistical Science, 2*(3), 317-335. [https://doi.org/10.1214/ss/1177013238](https://doi.org/10.1214/ss/1177013238){:target="_blank"}
- Berger, J. O., & Sellke, T. (1987). Testing a Point Null Hypothesis: The Irreconcilability of P Values and Evidence. *Journal of the American Statistical Association, 82*(397), 112-122. [https://doi.org/10.2307/2289131](https://doi.org/10.2307/2289131){:target="_blank"}
- Berger, J. O. (2003). Could Fisher, Jeffreys, and Neyman Have Agreed on Testing? *Statistical Science, 18*. [https://doi.org/10.1214/ss/1056397485](https://doi.org/10.1214/ss/1056397485){:target="_blank"}
- Fisher, Ronald A. (1935). *The design of experiments*. Oliver & Boyd
- Fisher, Ronald A. (1956). _Statistical methods and scientific inference: Vol. viii_. Hafner Publishing Co.
- Gigerenzer, G., Krauss, S., & Vitouch, O. (2004). The Null Ritual: What You Always Wanted to Know About Significance Testing but Were Afraid to Ask. In*The Sage handbook of quantitative methodology for the social sciences* (pp. 392-409). SAGE Publications, Inc. [https://doi.org/10.4135/9781412986311.n21](https://doi.org/10.4135/9781412986311.n21){:target="_blank"}
- Greenland, S. (2023). Divergence versus decision <i>P</i>-values: A distinction worth making in theory and keeping in practice: Or, how divergence <i>P</i>-values measure evidence even when decision <i>P</i>-values do not. *Scandinavian Journal of Statistics, 50*(1), 54-88. [https://doi.org/10.1111/sjos.12625](https://doi.org/10.1111/sjos.12625){:target="_blank"}
- Hubbard, R., & Bayarri, M. J. (2003). P Values are not Error Probabilities (*Duke University Working Papers Series*, Issue 2003-26). 
- Lakens, D. (2024). *Improving Your Statistical Inference* (1.4.5 ed.). URL:[https://lakens.github.io/statistical_inferences](https://lakens.github.io/statistical_inferences){:target="_blank"}
- Morimoto, R. (2021). Stop and Think About p-Value Statistics: Fisher, Neyman, and E. Pearson Revisited. *Annals of the Japan Association for Philosophy of Science, 30*, 43-65. [https://doi.org/10.4288/jafpos.30.0_43](https://doi.org/10.4288/jafpos.30.0_43){:target="_blank"}
- Perezgonzalez, J. D. (2015). Fisher, Neyman-Pearson or NHST? A tutorial for teaching data testing [Review]. *Frontiers in Psychology*, 6. [https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00223](https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00223){:target="_blank"}
- Spanos, A. (2003). *Probability Theory and Statistical Inference (Econometric Modeling with Observational Data)*: CAMBRIDGE UNIVERSITY PRESS.

[^1]: Fisher의 test는 Francis Edgeworth의 연구와 Karl Pearson의 연구를 바탕으로 한다고 알려져 있다 (Spanos, 2003, 14.2.4절). Fisher 이전의 가설검정에 관한 내용은 추후 공부하여 정리해보고 싶다.
[^2]: 이 논리가 옳지 않다는 주장에 대해서는 Hubbard & Bayarri (2003); Berger & Delampady(1987), 4.6절; Berger & Selke (1987)을 보라.
[^3]: "Either an exceptionally rare chance has occurred, or the theory of random distribution is not true"
[^4]: 참고로, Egon Pearson은 Karl Pearson의 아들이다.
[^5]: Neyman과 Pearson은 임의의 특정한 시행에서는 error가 발생했는지 알 수 없으므로 long-run probability, 즉 (long-run) type I error를 중요하게 다루어야 한다고 주장한다. 여기서 long-run probability란  특정한 statistical experiment를 셀 수 없이 많이 반복하여 계산된 확률을 의미한다. 즉 "type I error rate ($\alpha$)이 $0.05$이다"라는 진술은 statistical experiment를 반복적으로 여러 번 시행하여 수행한 test 결과의 $5\%$는 type I error라는 의미이다. 가령 $10,000$번의 동일한 시행으로 얻은 sample 그룹 $10,000$개로 $10,000$번의 test를 수행하였다고 하자. $\alpha = 0.05$는 각각의 시행에 대한 test의 결과 $10,000$번 중 $500$번의 검정 결과에서 type I error가 발생할 수 있다는 의미이다.
[^6]: "significantly different from zero"

[^7]: Morimoto (2021)에 따르면 Fisher는 $H_0$를 '수용 (accept)'한다는 개념이 논리적 오류라고 본다. Falsification (반증)은 논리적으로 타당한 후건 부정 (*modus tollens*; $P \rightarrow Q, \neg Q \therefore \neg P$)이지만, verification (검증)은 타당하지 않은 추론이라는 것이다. (Morimoto, 2021). Fisher라면 'Type II error는 $H_0$가 실제로 거짓일 때 $H_0$를 기각하지 못하는 (failure to reject) 오류로 정의된다'라는 말에 동의했을 지언정 'Type II error는 $H_0$가 실제로 거짓일 때 $H_0$를 수용하는 (accept) 오류로 정의된다'는 말에는 동의하지 않았을 것이며, 후자는 Neyman과 Pearson이 받아들일만한 정의였을 것이라고 Morimoto는 설명한다 (Morimoto, 2021). 가령 '모든 백조는 희다'라는 보편 진술 (universal statement)은 '어떤 백조는 검다'라는 관찰 내지 데이터에 의해 반증(falsify)된다. 하지만 '모든 백조는 희다'라는 보편 진술 자체가 검증될 수는 없다. 모든 백조를 전수조사하는 것은 불가능하기 때문이다. 내가 이해하기로는, 마찬가지로 어떤 통계 가설이 반증(falsification)된 이후에서야 우리는 그 가설이 거짓인 것처럼 행동할 수 있다. $H_0$가 기각된 이후 우리는 $H_1$이 잠정적으로 참인 것처럼 행동하게 되지만, $H_1$은 분포와 비교하여 기각될 수 없는 종류의 가설이기 때문에 $H_0$를 '수용 (accept)'한다는 개념은 타당하지 않다는 의미로 나는 이해하였다. 

[^8]: 내가 이해한 바로는, Fisher의 관점에서 $p$-value를 믿음의 '척도'로 본다면 이 척도가 적절한지 아닌지를 판단할 방법이 있어야 하고, $p$-value는 test statistics를 통해 계산되는 변수라는 점에서 test statistic이 적절한지 판단할 방법이 있어야 하지만, Fisher는 이에 관한 주제를 다루지 않는다. Fisher의 test가 $p$-value를 통해 $H_0$가 얼마나 믿을만한지에 대한 척도를 제공하는 한 이 문제가 해결되지 않으면 안된다. Neyman과 Pearson은 test를 애초에 $H_0$가 믿을만한지에 관한 척도로 보지 않기도 하고, test statistic이 적절한지 $\alpha$와 $\beta$를 기준으로 결정함으로써 문제를 해결한다는 것 같다.  
[^9]: 내가 이해하기로, N-P test에서 $\tau(\mathbf{x})$와 $c_\alpha$를 비교하는 것, 혹은 $p$와 $\alpha$를 비교하는 것은 data가 $H_0$ 통계 모델에서 나올 가능성이 얼마나 높은지 보려는 것이 아니다. 해당 시행에서 얻은 데이터를 바탕으로 $H_0$가 믿을만한지에 대한 척도를 세우려는 것도 아니다. 그저 해당 의사결정 규칙을 수없이 많이 사용했을 때 발생할 type I error의 long-run probability를 $\alpha$로 제한하려는 것이 목적이다. 
[^10]: Fisher의 test를 따라 p-value가 너무 낮으면 $H_0$를 신뢰하기 어렵게 만드는데, 이는 암묵적으로 다른 가설이 더 신뢰할만 하다는 것을 의미한다는 점에서 그런 것 같다.
[^11]: 사실 Spanos의 '다룬다' (operationalize)라는 서술이 무엇을 의미하는지는 잘 모르겠다. 
[^12]: Fisher가 이런 주장을 직접 하였는지에 관한 자료나 문헌은 찾지 못했음.. 아마도 Fisher test에서의 $p$-value에 대한 일반적인 설명인 듯하다.
