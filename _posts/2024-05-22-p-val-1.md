---
title: "[NHST] 1장. 통계적 가설검정의 개념"
tags: [statistics]
categories: blog
cover: /files/cover/2024-05-22-p-val-1.png
lang: ko
lang-ref: p-val-1
---
## 머리말
널리 사용되는 null hypothesis statistical testing (NHST)<sup>영가설 통계 검정</sup>은 학부 1학년 통계학 수업에서 배울 정도로 널리 사용되는 가설 검정법입니다. NHST는 Fisher의 test of significance와 Neyman-Pearson의 statistical hypothesis testing의 여러 요소들이 뒤섞여 만들어진 방법인데, 이 글에서는 두 방법의 핵심 개념들을 정리해보겠습니다.
<!--more-->

일반적으로 NHST는 null hypothesis<sup>영가설</sup> ($H_0$)과 alternative hypothesis<sup>대립가설</sup> ($H_1$)을 세우고, 실험을 통해 얻은 observed test statistics<sup>관측 검정통계량</sup>을 통해 $p$-value를 계산합니다. 계산된 $p$-value를 type I error rate<sup>1종 오류율</sup>인 significance level<sup>유의수준</sup>과 비교하여 $H_0$를 기각하거나 수용합니다. 

하지만 NHST를 공부하다 보면, 이해가 되지 않거나 헷갈리기 쉬운 지점들이 있습니다. $p$-value는 type I error를 저지를 확률인가요? 만약 type I error rate이 아니라면 어째서 maximum type I error rate인 $\alpha$와 비교하나요? $p$-value는 영가설<sup>null hypothesis</sup>($H_0$)이 참일 확률인가요? $\alpha$는 $0.05$, $\beta$는 $0.8$로 하는 이유가 있나요? 등등. 이 같은 물음에 답하기 위해서는 NHST가 하늘에서 뚝 떨어진 통계방법론이 아니라는 점에 주목할 필요가 있습니다. NHST는 Ronald Fisher가 제시한 test of significance<sup>유의성 검정</sup>, 그리고 Jerzy Neyman과 Egon Pearson이 제시한 statistical hypthesis testing<sup>통계적 가설검정</sup>의 요소들이 섞여있는 test입니다. 그래서 각각의 test가 무엇이고 어떻게 다른지 알아보는 것이 중요할 것 같습니다. 바로 이번 장에서 알아볼 내용입니다.

한편 NHST에 대한 비판도 상당히 많은 듯한데, 관습적으로 많은 저널과 기관에서 사용하고 있으니 NHST를 거부하기는 어려울 것 같습니다. 이왕 사용한다면 정확하게 아는 게 낫겠죠? 1장부터 4장까지 저의 서술은 주로 Daniël Lakens의 [「Improving Your Statistical Inferences」](https://lakens.github.io/statistical_inferences/){:target="_blank"}를 바탕으로 정리한 것입니다. 특히 1장은 두 test의 개념과 차이 등을 살펴보고자 Aris Spanos의 [「Probability Theory and Statistical Inference」](
https://doi.org/10.1017/CBO9780511754081){:target="_blank"}를 중심으로 정리하였습니다. 참고한 문헌들도 여럿 있고요.

처음 용어를 제시할 때는 영어 용어와 한국어 용어를 병기하였고, 이후로는 영어 용어를 사용하였음을 양해해주세요.

- 제가 통계학 전공자가 아니라는 점을 기억하시고, 이 글에 통계학적으로 잘못된 서술이 있을 수 있다는 점을 유념하여 비판적으로 읽어주길 바라요. 오류를 발견하면 언제든 이야기해주세요.
- 글의 내용을 다른 곳에 인용하실 때에는 이 **글의 출처와 함께 원문의 서지 정보를 필히 밝혀**주세요.  특히 **1-1, 1-2, 1-3절**의 내용을 인용할 때는 **Spanos (2003)의 서지정보를 명시**하도록 하고, 기타 **in-text citation이 명시된 항목**의 경우에도 **해당 서지정보를 함께 밝혀**주길 바랍니다. 연구, 아이디어, 주장 등은 한 사람이 뚝딱 생각하여 만드는 것이 아니라 선행 문헌들 위에서 발전되어 온 것들입니다 (a.k.a. 거인의 어깨). 원 문헌을 저술한 저자를 명시하여 그들이 받아 마땅한 공을 밝히도록 합시다.

**Null Statistical Hypothesis Testing** 정리하기 (1/4)

[1장. 통계적 가설검정의 개념]({% post_url 2024-05-22-p-val-1 %}) **←**

[2장. p-value의 특징]({% post_url 2024-05-23-p-val-2 %})

[3장. p-value를 제대로 보고하기]({% post_url 2024-05-28-p-val-3 %})

[4장. p-value와 error rate에 대한 오해와 물음]({% post_url 2024-05-29-p-val-4 %})


## 1-1. Fisher's Test of Significance
Fisher의 test of significance<sup>유의성 검정</sup>은 Neyman-Pearson의 statistical hypothesis testing<sup>통계적 가설검정</sup>보다 먼저 나온 방법입니다. Neyman과 Pearson이 Fisher의 방법을 보완하고자 제시한 것이 statistical hypothesis testing이기 때문이죠. 먼저 Fisher의 방법을 살펴본 이후 Neyman-Pearson의 방법을 알아보겠습니다.

### 개념과 과정

 Ronald Fisher가 제시한 test of significance<sup>유의성 검정</sup>는 다음과 같이 진행됩니다[^1]. 

1. **Null hypothesis<sup>영가설</sup> $\mathbf{H_0}$를 정합니다**. 이때 $H_0: \theta = \theta_0$의 형태로 나타낼 수 있습니다.

	- $H_0$는 효과가 없다고(null) 가정했을 때의 가설을 말합니다. 그래서 *null* hypothesis이죠.
	- 그렇다고 $H_0$가 반드시 효과가 없다는 내용일 필요는 없습니다. $H_0: \mu_1 - \mu_2 = 0$과 같이 효과가 없는 경우일 수도 있지만, $H_0: \mu_1 - \mu_2 = 6$이나 $r = 0.4$와 같이 특정한 값을 갖는 경우도 $H_0$가 될 수 있습니다. Null hypothesis가 *효과없음*을 의미하는 가설만을 칭한다고 오해되기 쉬워서, **target hypothesis**와 같이 더 포괄적인 용어를 사용해야 한다고 보는 의견도 있습니다 (Greenland, 2023).
	- 보다 중요한 것은 **$\mathbf{H_0}$가 sampling distribution<sup>표본 분포</sup>에 관한 정보를 담고 있어야** 한다는 점입니다. 다시 말해 $H_0$는 test statistic<sup>검정 통계량</sup> $\tau(\mathbf{X})$의 sampling distribution을 특정할 수 있는 조건을 기술합니다. 왜 그래야 할까요? 바로 test of significance의 근간이 되는 원리: $H_0$가 참이라는 전제 하에 정해진 sampling distribution에서 우리가 관찰하여 얻은 test statistic이 어디쯤 위치하는지 알기 위함입니다. 이를 통해 $H_0$가 참이라는 전제 하에서 관측된 statistic이 얼마나 드문지 알 수 있는 것이지요. 

2. 목적에 맞는 **test statistics를 정합니다**.

	 - 이때 *test statistic* $\tau(\mathbf{X})$는 $H_0:\theta = \theta_0$가 맞다는 가정 하에 그 distribution이 알려져 있어야 합니다. 앞서 강조했듯, 우리가 관찰하여 얻은 test statistic이 해당 sampling distribution에서 얼마나 드문지 알기 위함입니다.

3. **$\textbf{p}$-value를 계산합니다**. 이때 $p$-value는 statistic $\tau(\mathbf{X})$의 관측값인 $\tau(\mathbf{x})$의 tail-area probability로 계산됩니다.

	- 즉 $p\text{-value} = P(\tau(\mathbf{X}) \ge \tau(\mathbf{x})\mid H_0)$ 로서, sampling distribution에서 test statistic의 관측값과 그 이상의 극단적인 값이 관측될 확률을 의미합니다.

4. **$\mathbf{p}$-value를 해석합니다**. 

	- $H_0$가 참이라고 가정된 distribution (null model)에서, $p$-value가 작다면 (1) test statistic이 관측된 상황이 매우 드문 event이거나, (2) 가설로 상정된 $H_0$가 타당하지 않은 가설이거나의[^3] 두 경우로 해석될 수 있습니다[^2].
	- 현실적으로 연구자는 (1)보다는 (2)의 해석을 택하여 **$p$-value를 null hypothesis가 믿을만한지에 관한 척도로** 사용할 수 있습니다. $p$-value는 작으면 작을수록 $\tau(\mathbf{x})$가 $H_0$ 하에서 관측될 법하지 않기 때문에, $H_0$를 믿지 않을 이유가 더 커지는 것으로 이해됩니다. 
	- Fisher의 방법을 통해 알 수 있는 것은 **$H_0$ 하에서 연구 결과가 나타날 확률**입니다. 그러므로 Fisher의 $p$-value는 $H_0$를 잘못된 것으로 *기각*하거나 $H_0$에 반대되는 가설을 *지지*하는 **의사결정에 관한 방법이 아닙니다**. 
	- 어떤 $p$-value가 작은 값인지 아닌지에 관해서 Fisher는 초기 저작과 후기 저작에서 의견을 달리합니다.

		- 초기에 Fisher는 significance level을 관습적으로 5%로 제시하며 유의하지 않은 결과는 무시되어야한다고 봅니다 (Fisher, 1935, p.13, 재인용:Gigerenzer et al., 2004).
		- **Fisher는 이후** $p$-value가 얼마나 작아야하는가에 관해서는 **연구마다, 연구자마다 다를 수 있다**고 하며 $p$-value의 값을 **그대로 보고하여** 동료 연구자와 공유해야한다고 봅니다 (Fisher, 1956, p. 42, 재인용: Gigerenzer et al., 2004).

### 목적
Fisher's test of significance를 통해 얻은 $p$-value는 **observed statistic과 그 이상의 극단값이 null model 하에서 나올 확률**로서, 검정하고자 하는 **null hypothesis가 얼마나 믿을만한지에 대한 정립된 척도**를 제공합니다 (Fisher, 1956, p. 44). $p$-value는 작으면 작을수록 $\tau(\mathbf{x})$가 $H_0$ 하에서 관측될 법하지 않기 때문에 $H_0$를 받아들이지 않을 이유가 더 커지는 것으로 이해되는 것이지요.

## 1-2. Neyman-Pearson's Statistical Hypothesis Testing

Jerzy Neyman과 Egon Pearson[^4]은 $p$-value에 대한 Gosset과 Fisher의 연구를 바탕으로 **statistical hypothesis testing**이라는 방법을 개발합니다. Fisher의 test of significance와는 달리 alternative hypothesis<sup>대립가설</sup>($H_a$; $H_1$)이 설정되고, 연구자는 잠정적으로 $H_0$와 $H_1$ 두 가설 중 하나가 참인 것처럼 받아들이게 됩니다.

### 개념과 과정

Neyman–Pearson의 statistical hypothesis testing은 다음과 같이 진행됩니다 (Spanos, 2003, 14.3절).

1. **Null hypothesis $H_0$와 alternative hypothesis $H_1$를 정합니다**.

	- 각각 $H_0: \theta = \theta_0$ 와 $H_1: \theta \ne \theta_0$로 표현됩니다. 
	- 이때 parameter space<sup>모수 공간</sup> $\Theta$는 mutually exclusive한<sup>상호배타적인</sup> 두 부분집합으로 분할됩니다:

		$$\Theta_0 := \{\theta_0\}\text{ and }\Theta_1 := \Theta -\{\theta_0\},\quad \text{where } \Theta_0\cap\Theta_1 = \varnothing, \Theta_0\cup \Theta_1 = \Theta$$

	- 더 일반적인 Neyman-Pearson hypothesis의 형태는 다음과 같습니다:

		$$H_0: \theta \in \Theta_0 \text{ against }H_1: \theta \in \Theta_1:=\Theta -\Theta_0 $$

	- 이는 사실상 postulated probability model $\Phi = \{f(x;\theta), \theta\in\Theta, x\in \mathbb{R}_X\}$을 양분하는 것입니다:

		$$\Phi_0 = \{f(x;\theta), \theta\in\Theta_0, x\in \mathbb{R}_X\}, \Phi_1 = \{f(x;\theta), \theta\in\Theta_1, x\in \mathbb{R}_X\}$$

		$H_0$와 $H_1$이 궁극적으로는 parameter에 관한 가설이라기보다 *distribution*에 관한 가설이라는 점을 알 수 있겠습니다.

		$$H_0:f(x)\in \Phi_0\text{ against }H_1:f(x)\in\Phi_1 $$

2. **Rejection region**을 정합니다.

	- Neyman–Pearson test의 주된 목적은 $H_0$를 **수용하거나 기각하기 위한 결정 규칙** (decision rule)을 만드는 것입니다. 이 결정은 test statistic $\tau(\mathbf{X})$를 기준으로 하므로, $\tau(\mathbf{X})$는 sample space $\mathcal{C}$를 두 집합 $C_0$와 $C_1$로 분할하게 됩니다.
	- $C_0:=\lbrace\mathbf{x}:\tau(\mathbf{x}) \le c_\alpha\rbrace$로 표현되어 acceptance region<sup>수용역</sup>이라 불리고, $C_1:=\lbrace\mathbf{x}:\tau(\mathbf{x}) > c_\alpha\rbrace$로 표현되어 rejection region<sup>기각역</sup>이라 불립니다.
	- 각각 	$C_0 \cup C_1 = \mathcal{C}$ and $C_0 \cap C_1 = \varnothing$ 을 만족하는 것을 알 수 있겠습니다.
	- $H_0$를 수용할지 기각할지에 관한 결정은 두 region의 측면에서 정해집니다:

		$$\text{(i) if } \mathbf{x}\in C_0:\text{accept }H_0,\quad \text{(ii) if } \mathbf{x}\in C_1:\text{reject } H_0$$

3. **Type I error와 type Ⅱ error**

	1. 두 종류의 error가 있습니다.
		- **type I error**<sup>1종 오류</sup>: Null hypothesis가 타당한데<sup>valid</sup> 이를 기각하는 오류
		- **type Ⅱ error**<sup>2종 오류</sup>: Null hypothesis가 타당하지 않은데<sup>not valid</sup> 이를 수용하는 오류

	2. **Probability of type I error**

		$\theta_0 = \theta$ 일 때 type I error를 저지를 확률은 다음의 일반적인 형태로 표현될 수 있습니다:

		$$P(\mathbf{x} \in C_1; \theta = \theta_0) = \alpha$$

		- $\alpha$는 long-run type I error로서, 연구자가 최대로 허용할 수 있는 type I error probability를 의미합니다[^5]. 
		- Rejection region이 넓을 수록 $\alpha$는 줄어들지만, 이는 type II error의 확률을 증가시키게 됩니다.

	3. **Probability of type Ⅱ error**

		$\theta = \theta_1$일 때 type II error를 저지를 확률은 다음의 일반적인 형태로 표현될 수 있습니다:

		$$P(\mathbf{x}\in C_0; \theta = \theta_1) = \beta(\theta_1) $$

		- 이때 test statistic의 distribution을 알아야 확률을 계산할 수 있는데, $\Theta_1:=\Theta -\Theta_0$  의 값을 특정해야 distribution을 알 수 있겠죠? 그래서 위의 식에서 $\beta(\theta_1)$은 $\beta$가 $\theta_1$에 따라 정해진다는 의미입니다.
		- $\alpha$와는 달리, $\beta$는 rejection region이 넓을 수록 증가합니다.
		- $\alpha$가 커지면 $\beta$가 줄어들고, $\beta$가 커지면 $\alpha$가 줄어다는 사실을 제가 만든 다음 그림으로 이해할 수 있겠습니다.

		<p align="left">
  			<img src="/files/img/alpha_beta.svg" width="60%">
		</p>

4. **최적의 test를 정합니다**

	1. Neyman–Pearson은 $H_0$를 $H_1$보다 더 중요하게 다룹니다. 즉 낮은 $\alpha$를 먼저 정하고, 이후에 $\beta$를 최소화하는 방향으로 test를 선택한다는 것이죠. 가령 연구자는 $\alpha  = 0.01$로 정해두고 이후 $\beta$를 최소화하는 test를 선택하게 됩니다. 
	2. 일반화하면 다음과 같습니다. $|\tau(\mathbf{X})| > c_\alpha$일 때 $H_0$를 기각한다면,  $\tau(\mathbf{X})$는 다음을 만족하도록 선택한다:		
		$$\begin{align}&\text{(a)}\quad P(|\tau(\mathbf{X})| > c_\alpha; H_0\text{ valid}) = \alpha\\
			&\text{(b)}\quad P(|\tau(\mathbf{X})| \le c_\alpha; H_1(\theta)\text{ valid}) = \beta (\theta)\text{ for }\theta \in \Theta_1 \text{ is minimized.}
			\end{align}  $$
	3. 이는 test의 power<sup>검정력</sup>를 고려하는 측면에서 이해될 수도 있습니다.

		- **Power of a test**<sup>검정력</sup>: 타당하지 않은 $H_0$를 기각할 확률로서, 어떤 값 $\theta_1 \in \Theta_1$에 대해 다음과 같이 쓸 수 있습니다:	
		
			$$P(\theta_1) = P(\mathbf{x}\in C_1;H_1\text{ valid})$$ 
			
		($H_1: \theta \ne \theta_0$에 대해 $\theta$가 가질 수 있는 값이 여럿이므로 $\theta_1$의 함수로 표현한 것입니다.)

		- 다시 말해, test의 power는 $H_1$이 타당할 때 $H_0$를 기각할 확률, 또는 family $\Phi_1 = \{f(x;\theta), \theta \in \Theta_1, x\in \mathbb{R}_X\}$에 실제 분포가 속할 확률을 의미합니다.
		- 전체 parameter space $\Theta$에서 정의한 **power function**은 다음과 같습니다: 

			$$ P_{n}(\theta) = P(\mathbf{x}\in C_1)\text{ for }\theta \in \Theta$$

		- 가설 $H_0: \theta = \theta_0$에 대해 significance level은 power function을 통해 정의될 수 있습니다:
			$$P_n(\theta_0) = \alpha$$

		- 만약 $\theta_0 \in \Theta_0$이고 $\Theta_0$가 한 개 이상의 원소를 가진다면, test의 **size**를 다음과 같이 정의합니다:
		
			$$\text{size of the test} =\alpha = \max_{\theta\in\Theta_0}P_n(\theta) $$ 
			
		그러므로 test의 size $\alpha$는 $\Theta_0$의 임의의 원소 $\theta_0$에 대해 $H_0$를 잘못 기각할 최대 확률을 의미합니다.
		- 가장 적절한 test는 $\alpha$가 정해진 이후, 모든 $\theta \in \Theta_1$에 대해 power를 최대로 하는 test입니다.
 
	4. Test statistic $\tau(\mathbf{X})$를 선택했다면 $H_0$ 하에서의 distribution을 통해 $\lvert\tau(\mathbf{X})\rvert$가 "0으로부터 유의하게 차이나"도록[^6] 하는 $c_\alpha$를 얻을 수 있습니다. 다음 식을 만족하는 $c_\alpha$를 구하는 것입니다:

		$$P(|\tau(\mathbf{X})| > c_\alpha;H_0\text{ valid}) = \alpha$$

		이런 이유로 $\alpha$는 **significance level**<sup>유의 수준</sup>이라고도 불립니다. 
	5. e.g. $\sigma^2$를 모르는 상황에서 $H_0: \mu = \mu_0$와 $H_1: \mu \ne \mu_0$를 test하고자 하는 상황을 가정해봅시다 (Two-sided test). 
		- Test statistic은 $\tau(\mathbf{X}):=\frac{\hat{\mu_n} - \mu_0}{s/\sqrt{n}} \sim St(n-1)$
		- Rejection region은 $C_1 = \lbrace\mathbf{x}: \lvert\tau(\mathbf{x})\rvert > c_\alpha \rbrace$
		- $c_\alpha$는 $\int_{c_\alpha}^\infty \phi(z)dz = \frac{1}{2}\alpha$ where $\phi(z)$ is Student's $t$ density (pdf).

5. **$H_0$와 $H_1$중 하나를 택합니다**
	- Acceptance region $C_0:=\lbrace\mathbf{x}:\tau(\mathbf{x}) \le c_\alpha\rbrace$ 에 대해 $\mathbf{x} \in C_0$일 때 $H_0$를 수용하고[^7], rejection region $C_1:=\lbrace\mathbf{x}:\tau(\mathbf{x}) > c_\alpha\rbrace$에 대해 $\mathbf{x}\in C_1$일 때 $H_0$를 기각합니다.
	- Neyman–Pearson의 test에서 $p$-value 자체를 사용하지는 않으나, 사실상 test statistic $\tau(\mathbf{x})$가  acceptance region 혹은 rejection region에 포함되는지는 $p$-value와 $\alpha$를 비교하여도 알 수 있습니다. 그러므로  $p < \alpha$일 때 $H_0$를 기각하고, $p \ge \alpha$일 때 $H_0$를 수용합니다. 단, $p$-value를 소위 'observed type I error rate' 등으로 이해하는 것은 잘못되었는데, 이에 관한 내용은 4장에서 다룰 것입니다.
	
### 목적
Neyman과 Pearson은 Fisher의 significance test를 다음 두 가지 이유에서 비판합니다 (Spanos, 2003).
- Fisher는 test statistic을 선택하는 기준을 제공하지 않는다. 각각의 $H_0$에 대해 여러 test statistic을 사용할 수 있는데, Fisher는 어떤 것이 가장 적절한 test statistic인지에 관한 방법을 설명하지 않는다.
- $p$-value를 $H_0$에 대한 믿음의 척도 (measure of credence)로 사용하는 것은 논리적 근거가 없다. 

이에 대한 해결책으로 Neyman과 Pearson은 **hypothesis testing을 경쟁하는 가설 중 하나를 선택하는 것**으로 봅니다[^8].

## 1-3.  Neyman–Pearson과 Fisher의 차이
1. Test의 **목적**이 다릅니다. 그래서 $\alpha$와 $p$-value는 그 성격이 다르지요. (Spanos, 2003, 14.5.1절)
	- Neyman–Pearson의 $\alpha$는 **의사결정(decision-making)이라는 행동**의 규칙이 되는 기준값입니다. 이때 $\alpha$는 significance level로서, test statistic이 $\alpha$보다 큰지 작은지에 따라 $H_0$를 수용하거나 기각하는 의사결정을 내리게 됩니다[^9]. 
	- 반면 Fisher의 $p$-value는 결정을 내리기 위한 기준이 아니라 sample data가 $H_0$를 얼마나 믿을만한 것으로 만드는지 **추정하기(inferential) 위한 척도**일뿐입니다. 그러므로  Fisher는 $p$-value를 통해 그 이상의 주장을 할 수 없다고 봅니다.
2. Test의 **범위**가 다릅니다 (Spanos, 2003, 14.5.2절).
	- Neyman–Pearson의 가설은 $H_0: \theta \in \Theta_0 \text{ against }H_1: \theta \in \Theta_1:=\Theta -\Theta_0$ 의 형태를 가지지요? 그래서 parameter space $\Theta$가 $\Theta_0$와 $\Theta_1$으로 분할되며 probability model $\Phi = \{f(x;\theta), \theta \in \Theta, x \in \mathbb{R}_X\}$는 $\Phi_0 = \{f(x;\theta), \theta\in\Theta_0, x\in \mathbb{R}_X\}$와 $\Phi_1 = \{f(x;\theta), \theta\in\Theta_1, x\in \mathbb{R}_X\}$로 분할되는 것입니다. 이제 Neyman–Pearson의 가설은 다음과 같이 이해될 수 있습니다:
	
		$$H_0:f(x)\in \Phi_0\text{ against }H_1:f(x)\in\Phi_1 $$

	- 반면 Fisher의 가설은 다음과 같이 이해됩니다: 
	
		$$H_0: f(x)\in \Phi_0\text{ against } H_1: f(x)\in [\mathcal{P}-\Phi_0] $$
		이때 $\mathcal{P}$는 *모든*  가능한 statistical model의 집합입니다. Fisher는 alternative hypothesis 개념을 거부하긴 했지만, 그의 test에 implicit<sup>암묵적인</sup> alternative hypothesis가 있다는 사실을 부정하기는 어려울 것입니다[^10]. 
	- Fisher의 implicit alternative hypothesis는 N–P test의 alternative hypothesis보다 범위가 넓습니다. 
		- 이는 강점이 될 수 있습니다. 연구자는 '참인' statistical model이 null hypothesis와 (implicit) alternative hypothesis의 합집합 안에 존재한다고 확신할 수 있기 때문입니다: 

			$$f(x) \in \mathcal{P} = \Phi_0 \cup [\mathcal{P}-\Phi_0] $$

			반면 N–P test에서는 '참인' statistical model이 null과 alternative 어디에도 존재하지 않을 수 있다는 점에서 그런 확신을 할 수 없습니다.
		- 이는 약점이 될 수도 있겠습니다.  집합 $[\mathcal{P-\Phi_0}]$는 달리 규정된 바가 없는 모든 가능한 모델의 집합이기 때문에 그만큼 다루기<sup>operationalize</sup> 어려울 수 있습니다. 반면 Neyman–Pearson의 $\Phi_1$은 power function의 측면에서 비교적 다루기<sup>operationalize</sup> 쉬울 수 있습니다[^11].
3. **Significance level**을 바라보는 관점이 다릅니다.
	- Neyman과 Pearson은 임의의 특정한 시행에서 error가 발생했는지 알 수 없으므로 **long-run probability**에 초점을 두어야 한다고 봅니다 (Perezgonzalez. 2015). 여기서 long-run probability란 특정한 statistical experiment를 셀 수 없이 많이 반복하여 계산된 확률, 즉  **relative frequency (상대빈도)** 로서의 확률을 의미합니다 (Spanos, 2003, p. 698). 
		- 그러므로 type I error rate ($\alpha$)이 $0.05$라는 말은, statistical experiment를 매우 많이 반복 시행하여 수행한 test 결과의 $5\%$가 type I error라는 의미입니다. 가령 $10,000$번의 동일한 시행으로 sample을 얻었다고 하죠. $\alpha = 0.05$는 각각의 시행에 대한 $10,000$개의 검정 결과 중 $500$번의 검정 결과에서 type I error가 발생할 수 있다는 의미인 것입니다
		- $\alpha$는 사전에 (*a priori*) 설정되어야 합니다. 
	- 이와 달리 Fisher의 접근은 **특정한 가설의 특정 연구 결과를 검정하고자** 하는 것이므로 long-run probability를 중요하게 보지 않습니다. 
		- Fisher는 관습적으로 사용하던 significance level의 사용을 반대하고, 그것을 long-run probability $\alpha$ 로 해석하는 것 또한 비과학적인 (unscientific) 것으로 여겨 반대합니다 (Fisher, 1956, p. 42, 재인용: Gigerenzer et al., 2004). 산업계의 quality-control과는 다르게, 연구자는 동일한 실험을 셀 수 없이 여러번 반복하지 않기 때문입니다. 
		- 이러한 측면에서 Fisher는 Neyman과 Pearson이 주장하듯 significance level을 long-run type I error rate으로 해석하는 것은 옳지 않다고 봅니다. 대신 그는 연구를 출판할 때 exact level of significance (e.g. $p < 0.05$ (x) $p = 0.02$ (o))를 명시하여 동료 연구자와 공유해야 한다고 주장합니다.
		- Fisher의 $p$-value는 사후에 조정될 수 있습니다. 개별 연구에서 $p$-value를 사후에 (*a posteriori*) 조정할 때 (e.g. Bonferroni correction) error의 영향이 효과적으로 통제될 수 있기 때문입니다[^12] (Perezgonzalez, 2015).
4. Null hypothesis statistical testing (NHST; 영가설 통계검정)에 이르러서는 Fisher의 signifance test와 Neyman–Pearson의 statistical hypothesis testing의 요소들이 서로 뭉쳐서 다루어지게 되는 듯합니다. 각각의 사례마다 해석되는 방식은 약간의 차이가 있는 듯 한데, 적어도 Fisherian test와 같이 통계적 유의성이라는 개념이 사용되고, N–P test와 같이 $H_0$와 $H_1$중 하나를 선택하는 결정을 내린다는 점은 공통적인 것 같습니다.

Fisher의 test와 Neyman–Pearson의 test의 차이에 관해서는 Perezgonzalez (2015)의 리뷰, Berger (2003)의 글, Morimoto (2021)의 글을 보길 바랍니다.

## Reference

- Berger, J. O., & Delampady, M. (1987). Testing Precise Hypotheses. *Statistical Science, 2*(3), 317-335. [https://doi.org/10.1214/ss/1177013238](https://doi.org/10.1214/ss/1177013238){:target="_blank"}
- Berger, J. O., & Sellke, T. (1987). Testing a Point Null Hypothesis: The Irreconcilability of P Values and Evidence. *Journal of the American Statistical Association, 82*(397), 112-122. [https://doi.org/10.2307/2289131](https://doi.org/10.2307/2289131){:target="_blank"}
- Berger, J. O. (2003). Could Fisher, Jeffreys, and Neyman Have Agreed on Testing? *Statistical Science, 18*. [https://doi.org/10.1214/ss/1056397485](https://doi.org/10.1214/ss/1056397485){:target="_blank"}
- Cox, D., & Mayo, D. G. (2010). Objectivity and conditionality in frequentist inference. In D. G. Mayo & A. Spanos (Eds.), *Error and Inference: Recent Exchanges on Experimental Reasoning, Reliability, and the Objectivity and Rationality of Science*. Cambridge University Press. 
- Fisher, Ronald A. (1935). *The design of experiments*. Oliver & Boyd
- Fisher, R. A. (1935b). Statistical Tests. *Nature, 136*(3438), 474. [https://doi.org/10.1038/136474b0](https://doi.org/10.1038/136474b0){:target="_blank"} 
- Fisher, Ronald A. (1956). _Statistical methods and scientific inference: Vol. viii_. Hafner Publishing Co.
- Gigerenzer, G., Krauss, S., & Vitouch, O. (2004). The Null Ritual: What You Always Wanted to Know About Significance Testing but Were Afraid to Ask. In*The Sage handbook of quantitative methodology for the social sciences* (pp. 392-409). SAGE Publications, Inc. [https://doi.org/10.4135/9781412986311.n21](https://doi.org/10.4135/9781412986311.n21){:target="_blank"}
- Greenland, S. (2023). Divergence versus decision <i>P</i>-values: A distinction worth making in theory and keeping in practice: Or, how divergence <i>P</i>-values measure evidence even when decision <i>P</i>-values do not. *Scandinavian Journal of Statistics, 50*(1), 54-88. [https://doi.org/10.1111/sjos.12625](https://doi.org/10.1111/sjos.12625){:target="_blank"}
- Hubbard, R., & Bayarri, M. J. (2003). P Values are not Error Probabilities (*Duke University Working Papers Series*, Issue 2003-26). 
- Lakens, D. (2024). *Improving Your Statistical Inference* (1.4.5 ed.). URL:[https://lakens.github.io/statistical_inferences](https://lakens.github.io/statistical_inferences){:target="_blank"}
- Morimoto, R. (2021). Stop and Think About p-Value Statistics: Fisher, Neyman, and E. Pearson Revisited. *Annals of the Japan Association for Philosophy of Science, 30*, 43-65. [https://doi.org/10.4288/jafpos.30.0_43](https://doi.org/10.4288/jafpos.30.0_43){:target="_blank"}
- Perezgonzalez, J. D. (2015). Fisher, Neyman-Pearson or NHST? A tutorial for teaching data testing [Review]. *Frontiers in Psychology*, 6. [https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00223](https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00223){:target="_blank"}
- Spanos, A. (2003). *Probability Theory and Statistical Inference (Econometric Modeling with Observational Data)*: CAMBRIDGE UNIVERSITY PRESS.

[^1]: Fisher의 test는 Francis Edgeworth의 연구와 Karl Pearson의 연구를 바탕으로 한다고 알려져 있습니다 (Spanos, 2003, 14.2.4절). Fisher 이전의 가설검정에 관한 내용은 추후 공부하여 정리해보고 싶네요.

[^2]: 이 논리가 옳지 않다는 주장에 대해서는 Hubbard & Bayarri (2003); Berger & Delampady(1987), 4.6절; Berger & Selke (1987)을 보세요.

[^3]: "Either an exceptionally rare chance has occurred, or the theory of random distribution is not true"

[^4]: 참고로, Egon Pearson은 Karl Pearson의 아들이에요.

[^5]: Neyman과 Pearson은 임의의 특정한 시행에서는 error가 발생했는지 알 수 없으므로 long-run probability, 즉 (long-run) type I error를 중요하게 다루어야 한다고 주장합니다. 여기서 long-run probability란  특정한 statistical experiment를 셀 수 없이 많이 반복하여 계산된 확률을 의미합니다. 즉 "type I error rate ($\alpha$)이 $0.05$이다"라는 말은 statistical experiment를 반복적으로 여러 번 시행하여 수행한 test 결과의 $5\%$는 type I error라는 뜻입니다. 가령 $10,000$번의 동일한 시행으로 얻은 sample 그룹 $10,000$개로 $10,000$번의 test를 수행하였다고 합시다. $\alpha = 0.05$는 각각의 시행에 대한 test의 결과 $10,000$번 중 $500$번의 검정 결과에서 type I error가 발생할 수 있다는 말인 것이죠.

[^6]: "significantly different from zero"

[^7]: Fisher는 '$H_0$를 수용<sup>accept</sup>'한다는 개념이 논리적 오류라고 봅니다 (Fisher, 1935, p. 16; Fisher, 1935b; Morimoto, 2021; Cox & Mayo, 2010). 이는 포퍼 (Popper)의 반증주의<sup>falsificationism</sup>와 비슷한데요, 반증<sup>falsification</sup>은 논리적으로 타당한 후건 부정 (*modus tollens*; $P \rightarrow Q, \neg Q \therefore \neg P$)이지만, 검증<sup>verification</sup>은 타당하지 않은 추론이라는 것입니다. (Morimoto, 2021). Fisher라면 'Type II error는 $H_0$가 실제로 거짓일 때 $H_0$를 **기각하지 못하는 (failure to reject) 오류로 정의된다**'라는 말에 동의했을 지언정, 'Type II error는 $H_0$가 실제로 거짓일 때 $H_0$를 **수용하는 (accept) 오류로 정의된다**'는 말에는 **동의하지 않았을 것**이며, 후자는 Neyman과 Pearson이 받아들일만한 정의였을 것이라고 Morimoto는 설명합니다 (Morimoto, 2021). 가령 '모든 백조는 희다'라는 보편 진술<sup>universal statement</sup>은 '어떤 백조는 검다'라는 관찰 진술에 의해 반증<sup>falsify</sup>됩니다. 하지만 '모든 백조는 희다'라는 보편 진술 자체가 검증<sup>verify</sup>되기는 매우 어려울 것입니다. 모든 백조를 전수조사하는 것은 불가능에 가깝기 때문입니다. 제가 이해하기로는, 마찬가지로 어떤 통계 가설이 반증(falsification)된 이후에서야 우리는 그 가설이 거짓인 것처럼 행동할 수 있습니다. $H_0$가 기각된 이후 우리는 $H_1$이 잠정적으로 참인 것처럼 행동하게 되지만, $H_1$은 분포와 비교하여 기각될 수 없는 종류의 가설이기 때문에 $H_0$를 '수용 (accept)'한다는 개념은 타당하지 않은 것입니다. 

[^8]: 제가 이해한 바로는, Fisher의 관점에서 $p$-value를 믿음의 '척도'로 본다면 이 척도가 적절한지 아닌지를 판단할 방법이 있어야 하고, $p$-value는 test statistics를 통해 계산되는 변수라는 점에서 test statistic이 적절한지 판단할 방법이 있어야 하지만, Fisher는 이에 관한 주제를 다루지 않습니다. Fisher의 test가 $p$-value를 통해 $H_0$가 얼마나 믿을만한지에 대한 척도를 제공하는 한 이 문제가 해결되어야 합니다. Neyman과 Pearson은 test를 애초에 $H_0$가 믿을만한지에 관한 척도를 알기 위해 사용하지 않고, test statistic이 적절한지 $\alpha$와 $\beta$를 기준으로 결정함으로써 문제를 해결한다는 것 같습니다.

[^9]: 제가 이해하기로는, N-P test에서 $\tau(\mathbf{x})$와 $c_\alpha$를 비교하는 것, 혹은 간접적으로 $p$와 $\alpha$를 비교하는 것은 data가 $H_0$ 통계 모델에서 나올 가능성이 얼마나 높은지 보려는 것이 아닙니다. 해당 시행에서 얻은 데이터를 바탕으로 $H_0$가 믿을만한지에 대한 척도를 세우려는 것도 아닙니다. 그저 해당 의사결정 규칙을 수없이 많이 사용했을 때 발생할 type I error의 long-run probability를 $\alpha$로 제한하려는 것이 목적인 것입니다.

[^10]: Fisher의 test를 따라 p-value가 너무 낮으면 $H_0$를 신뢰하기 어렵게 만드는데, 이는 암묵적으로 다른 가설이 더 신뢰할만 하다는 것을 의미한다는 점에서 그런 것 같습니다.
[^11]: 사실 Spanos의 '다룬다' (operationalize)라는 서술이 무엇을 의미하는지는 잘 모르겠어요. 
[^12]: Fisher가 이런 주장을 직접 하였는지에 관한 자료나 문헌은 찾지 못했음.. 아마도 Fisher test에서의 $p$-value에 대한 일반적인 설명인 듯합니다.
