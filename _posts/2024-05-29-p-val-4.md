---
title: "[NHST] 4장. NHST에 대한 오해와 물음들"
tags: [statistics]
categories: blog
---

## 머리말
지금까지 frequentist test에서 사용되는 개념, 방법, $p$-value의 특징과 의미를 살펴보았습니다. 이번 절에서는 NHST에 관한 오해와 질문들을, 특히 $p$-value에 관해서 살펴보겠습니다.
<!--more-->

이 절은 Greenland et al. (2016)의 글 'Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations'와 Daniël Lakens의 「[Improving Your Statistical Inferences](https://lakens.github.io/statistical_inferences/)」를 참고하여 정리한 내용입니다.

- 제가 통계학 전공자가 아니라는 점을 기억하시고, 이 글에 통계학적으로 잘못된 서술이 있을 수 있다는 점을 유념하여 비판적으로 읽어주길 바라요. 오류를 발견하면 언제든 이야기해주세요.
- 글의 내용을 다른 곳에 인용하실 때에는 이 **글의 출처와 함께 원문의 서지 정보를 필히 밝혀**주세요. 

**Null Statistical Hypothesis Testing** 정리하기 (4/4)

[1장. 통계적 가설검정의 개념]({% post_url 2024-05-22-p-val-1 %}) 

[2장. p-value의 특징]({% post_url 2024-05-23-p-val-2 %})

[3장. p-value를 제대로 보고하기]({% post_url 2024-05-28-p-val-3 %})

[4장. p-value와 error rate에 대한 오해와 물음]({% post_url 2024-05-29-p-val-4 %}) **←**

NHST에 관해 갖는 흔한 오해에는 무엇이 있고, 왜 그것이 오해인지 알아볼까요?

## 4-1. P-value를 hypothesis에 대한 확률로 해석할 수 없다.
 **$p$-value는 $H_0$에 대한 확률이 아닙니다** ([Greenland et al., 2016](#9cd7a5)).  $p$-value는 $P(Data\mid H_0)$이지, $p(H_0\mid Data)$가 아니기 때문입니다. 즉, $p$-value는 이미 $H_0$가 참이라는 가정 하에 계산되었으므로, $H_0$가 참이거나 거짓일 확률과는 무관합니다.
1. **오해: "$p$-value가 통계적으로 유의하지 않을 때 null hypothesis ($H_0$)가 참이다"** **(X)**
	1. "$p$-value가 유의하지 않을 때 $H_0$가 참이다"라는 진술은 $H_0$가 참일 확률이 100%라는 의미를 내포합니다. 이는 $p$-value가 $H_0$에 대한 확률에 대해 말해주는 것이 있다는 의미이므로 잘못된 진술입니다.
	2. $p$-value가 통계적으로 유의하지 않더라도, observed test statistic이 null model보다 alternative model에서 나올 가능성이 더 높을 수 있습니다.
    
		<p align="left">
			<img src="/files/img/normal_two.svg" width="80%">
		</p>

2. **오해: "$p$-value가 통계적으로 유의하다면 null hypothesis ($H_0$)가 거짓이다"** **(X)**
	1. "$p$-value가 유의할 때 $H_0$가 거짓이다"라는 진술은 $H_0$가 거짓일 확률이 100%라는 의미를 내포합니다. 이는 $p$-value가 $H_0$에 대한 확률에 대해 말해주는 것이 있다는 의미이므로 잘못된 진술입니다.
	2. $p$-value가 통계적으로 유의하더라도 $H_0$가 사실은 참이었을 가능성을 배제할 수 없습니다. 즉, test 결과로 $H_0$를 기각하는 행위가 type I error일 가능성을 배제할 수 없다는 말입니다. Neyman–Pearson은 이 상황을 두고 "null hypothesis가 거짓인 것처럼 *행동*하자 (*act* as if the null hypothesis is false)"고, "장기적으로 우리가 틀릴 확률은 5%가 안될 것이다 (not be wrong more than 5% of the time in the long run)."라고 결론 내리겠죠? $H_0$가 참 또는 거짓인 것처럼 *행동 (act)* 하는 것은 $H_0$가 참이나 거짓이라고 믿는 것과는 다릅니다 ([Lakens, 2024, 1.7절](#83ef58)).  
	3. 작은 $p$-value는 **$H_0$ 를 포함한 모든 가정이 만족된 모델 상**에서 관측 데이터가 드문 (unusual) 경우임을 나타냅니다. 그러므로 $p$가 작다고 하여 관측한 데이터가 드문 경우라고 바로 결론 내릴 수는 없습니다[^1]. Random error가 매우 큰 경우이거나, 만족되었다고 간주된 가정이 사실은 위배된 경우일 수 있기 때문입니다. 특히 이때의 가정들은 test statistics에 관한 가정뿐만 아니라 표본 추출, 실험군 배정 및 결측치 발생에서의 무작위성 (randomness)에 관한 가정, 나아가 $p$-value가 연구결과 보고를 위해서 임의의 기준에 따라 선택되지 않았다는 가정 또한 포함합니다 ([Greenland, 2016](#9cd7a5)).
3. **오해: "$p = 0.03 < \alpha$로  통계적으로 유의한 경우, 이 결과가 type I error일 확률은 3%이다"** **(X)**
	1. "$p$-value가 type I error rate이다"라는 진술은 $p$-value가 $H_0$가 참일 때 잘못 기각하는 확률이라는 의미로서, 이는  $p$-value가 $H_0$에 대한 확률에 대해 말해주는 것이 있다는 의미이므로 잘못된 진술입니다.
	2. $H_0$가 참인데 우리가 얻은 test 결과가 $p = 0.03 < \alpha$라면, 이것은 100% type I error인 것이죠. 
	3. $p$-value와 $\alpha$ 모두 $H_0$가 참인 null model에서의 tail-area probability이며 $p$와 $\alpha$를 비교하여 의사결정을 한다는 점에서 $p$-value가 data를 기반으로 계산된 type I error rate인 것으로 이해하기 쉽지만, 이는 $p$-value라는 개념을 잘못 이해한 것입니다. ([Goodman, 1999](#aa0559)). 
	4. "$p<0.05$를 얻었을 때 $H_0$가 참 (또는 거짓)일 확률은 무엇인가?"라는 질문은 "$H_0$가 참일 때 우리가 얻은 데이터 (또는 그보다 더 극단적인 데이터)를 얻을 확률은 무엇인가?"라는 질문과 다릅니다. $p$-value는 두 번째 질문에 대한 답만을 줄 수 있습니다 ([Lakens, 2024, 1.7.4절](#83ef58)).

## 4-2. p-value가 통계적으로 유의한지는 '실제로' 중요한지와는 무관하다.
- $p$-value가 통계적으로 유의한지, 즉 $p<\alpha$인지 아닌지는 effect size의 크기와는 무관합니다. $p < 0.05$라거나 $p = 0.002$와 같은 $p$-value만으로는 평균의 차이가 얼마나 나는지 알 수 없죠. 그래서 통계적으로 유의하다고 반드시 실제로 혹은 임상에서 의미있는 정도의 효과가 아닐 수 있고, 그 반대의 경우도 마찬가지입니다.
- 즉, 통계적으로 유의한 결과는 null model하에서 '놀라운 (surprising)'결과인 것이지, 반드시 '중요한' 결과는 아닐 수 있습니다.
- 설령 effect의 크기가 중요하다고 하더라도, sample size가 큰 경우 effect size가 매우 작거나 가정이 약간이라도 위배되었을 때 통계적으로 유의하다는 결과가 나올 수 있습니다 ([Greenland, 2016](#9cd7a5)).  

## 4-3. P-value는 효과가 재현될 확률이 아니다.
- 하나의 연구에서 얻은 $p$를 바탕으로 효과가 재현될 확률을 계산하는 것은 불가능합니다. 효과가 재현될 확률은 미래의 sample를 대상으로 하는 test 결과에 관한 것이므로, 전체 population에 대한 지식을 알지 못하면 계산할 수 없습니다 ([Miller, 2009](#5d12f0)). $p$-value는 현재 sample만으로 얻어진 값이므로, 이를 통해 소위 replication probability를 도출하는 것은 말도 안되는 것입니다.
- 실제 효과가 있을 때, 어떤 test가 통계적으로 유의한 효과를 보일 확률은 power입니다 ([Lakens, 2024, 1.7.5절](#83ef58)).
- 실제 효과가 없을 때, 어떤 test가 통계적으로 유의한 효과를 보일 확률은 $\le \alpha$입니다 ([Lakens, 2024, 1.7.5절](#83ef58)).

## 4-4. P-value는 우리의 데이터가 나올 확률이 아니다.
1.  $p$-value는 모든 가정이 만족되고 $H_0$가 참일 때 우리가 관측한 데이터 (혹은 통계량)이 나올 확률이 아닙니다. 이는 $p$-value의 정의를 보면 바로 알 수 있습니다. $p$-value는 $P(\tau(\mathbf{X}) \ge \tau(\mathbf{x})\mid H_0)$ 로서, $H_0$하의 null model에서 test statistic의 관측값이 나오는 것 뿐만 아니라 *그 이상의 극단적인 값이 관측될* ("observations more extreme than what we observed") 이론적 확률을 의미하기 때문입니다.
2. 이에 관해서는 [1-1절]({% post_url 2024-05-22-p-val-1 %}#1-1-fishers-test-of-significance){:target="_blank"}의 "$p$-value가 작다면 (1) test statistic이 관측된 상황이 매우 드문 사건이거나, (2) 가설로 상정된 null hypothesis가 타당하지 않은 가설이거나의 두 경우로 해석될 수 있다"라는 진술의 (1)이 통계학적으로 아주 엄밀한 문장은 아니라는 점을 짚어볼 필요가 있습니다.
	- "Either $H_0$ is true and a rare event has occured, or $H_0$  is false"라는 논리에서 'rare event'는 실제 관측통계량 $\tau(\mathbf{x})$를 관측하는 event가 아니라, 실제 관측통계량과 그보다 더 극단적인 ("more extreme") 통계량을 얻는 event $$ E = \{\text{possible data }x: \lvert\tau(\mathbf{X})\rvert \ge \lvert\tau(\mathbf{x})\rvert\}$$입니다. 그래서 'rare event'가 test statistic이 관측된 상황, 즉 $\tau(\mathbf{x})$를 관측하는 event라고 말하는 것은, $E$와 $\mathbf{x}$를 구별하지 않는 것입니다 ([Berger & Delampady, 1987](#89420d)).
	- 이때 $\mathbf{X} = \mathbf{x}$라고 하는 것과 $\mathbf{X} \in E$라고 말하는 것에는 차이가 있습니다. $\mathbf{X} \in E$는 $H_0$를 기각할 **훨씬 더 강한 증거**라는 점에서 그렇습니다
		- 가령 '동전의 앞뒷면이 나올 확률이 $0.5\%$로 같다'라는 명제가 $H_0$라 합시다. 동전을 $100$번 던져서 앞면이 $60$번 나왔습니다. $\mathbf{X} = \mathbf{x} = 60$은 $H_0$를 적당히 신뢰하지 않을 정도라는 생각을 들게 하지만, $\mathbf{X} \in E$는 100번 중 60번 *이상의 극단 값*에서 앞면이 나왔다는 의미로서 $H_0$를 신뢰하지 않을 이유가 더 강해지는 것입니다.
		- ~~Berger와 Selke는 $P(H_0\mid E)$가 흔히 $P$-value와 매우 가까워서 $P(H_0\mid \mathbf{x})$보다 작다는 것을 보인 바 있다 ([Berger & Selke, 1987](#3cc52e)).~~ (레퍼 직접 읽고 이해하고 확인해야함.)

## 4-5. alpha는 발표된 연구 중 type I error가 있을 확률이 아니다.
이 항목은 Lakens의 글 2.2절을 주로 참고하였습니다.
$\alpha = 0.05$일 때 발표된 연구의 최대 $5\%$가 type I error일 것이다' 라는 진술은 거짓입니다. 
1. Type I error rate은 '실제로는 효과가 없을 때 효과가 있다고 잘못 결론짓는 오류 확률'로서, '연구가 통계적으로 유의한 결과를 보였을 때 그것이 실제 효과가 있을 확률'과는 구별됩니다.
	-  $\alpha = P(\text{statistically significant result }\mid \text{ no actual effect})$ 인 반면, 
	- 해당 물음은 $P(\text{no actual effect } \mid \text{ statistically significant result})$를 의미하는 것이죠.
2. 후자의 확률은 **false positive report probability (false positive risk; false discovery rate)** 라 불리고, 이와 반대되는 확률은 **positive predictive value (PPV)** 로 불립니다. $$\begin{align}PPV &= \frac{\text{True Positives}}{\text{True Positives + False Positives}}\\\\FDR = FPRP &= \frac{\text{False Positives}}{\text{True Positives + False Positives}}\end{align}$$
3. 연구 결과는 통계적으로 유의한 결과와 그렇지 않은 결과 모두를 얻게 되지만, 연구를 발표할 때는 통계적으로 유의한 결과 위주로 보고하는 편향이 발생하곤 합니다. 그래서 $\alpha = 0.05$로 하는 test를 수행하여도, 실제 보고되는 결과는 통계적으로 유의한 결과가 위주가 되므로 $FDR$는 $5\%$보다 클 수 있습니다.

## 4-6. p-value는 증거의 척도 (measures of evidence)인가?
1. Lakens는 $p$-value를 *증거*의 척도 (measures of *evidence*)로 해석하는 것이 통계학적으로 옳지 않다고 설명합니다. 
	1. $H_0$가 실제로 참일 때 $p$-value가 uniform distribution을 따른다는 사실과 Lindley's paradox를 고려하면, $p$-value 단독을 증거의 척도로 이해하는 것은 옳지 않습니다.
	2. $p$-value가 증거의 척도라고 주장하는 이들은 '증거' (evidence)의 개념을 정의하지 않습니다.
		- Lakens는 '증거 (evidence)'에 관한 Shafer의 이론을 따라서, 증거 (evidence)가 support function을 통해 정량될 수 있고, 통계적 증거를 평가할 때에 support는 likelihood function을 통해 정량될 수 있다고 설명합니다 ([Shafer, 1976, p. 144](#1b1f90). 재인용: [Lakens, 2024, 1.6절](#83ef58))[^2].
2. 한편 Greenland는 $p$-value가 **증거의 척도로 쓰이는 경우**와 **의사결정을 위한 random variable로 쓰이는 경우**로 구별되어 이해될 수 있다고 봅니다 ([Greenland, 2023](#30bdb1)). $p$-value가 증거의 척도가 아니라고 주장하는 이들은 Neyman–Pearson framework에서의 $p$-value에만 초점을 두고 있다는 것이지요.
	 1. Greenland에 따르면 frequentist statistics에서 사용하는 $P$-value는 두 가지 정의가 있습니다.
		- **divergence $p$-value**: Model과 observed statistics 간의 차이를 나타내는 $p$-value. 즉, 데이터와 모델의 차이 (divergence)를 나타냅니다. 
		- **decision $p$-value**: 전체 sample space에 걸쳐 이분법적 결정 규칙을 표현하기 위한 random variable로서의 $p$-value 또는 그러한 random variable의 관측값. Decision $p$-value는 $H_0$와 $H_a$ 중 하나를 고르기 위해 사용됩니다. 
	2. 증거 (evidence)의 정의에 관한 단일한 합의점은 없지만, Fisher의 framework에서 $p$-value는 observed **data와 null model 사이의** compatibility 내지 **divergence에 대한 일관된 척도(coherent measures)** 로서, 어떠한 모델이나 가설에 대항하는(against) 증거의 척도 (measure of evidence)로 사용될 수 있다고 보여집니다.

저는 잠정적으로 Greenland의 설명이 더 설득력있다고 생각합니다. [Lavine (2024)](#a0c299)의 연구와 같이 $p$-value가 증거의 척도가 아니라고 주장하는 문헌이 여럿 있고 살펴볼 필요가 있어 보이는데, 적어도 Lakens의 지적은 충분하지 않은 것 같습니다. $H_0$가 참일 때 $p$-value가 uniform distribution을 따르고 Lindley's paradox가 존재한다는 점이 보여졌다고 하여도, 이는 Neyman-Pearson framework에서의 지적이기 때문입니다. Fisherian framework에서는 $p$-value가 개별 실험의 관측값과 모델 간의 양립가능성(compatibility)을 나타내는 척도로 이해되지 못할 이유가 없는 것 같네요.

물론 두 관점을 적절하지 않게 혼동하는 일은 없어야 하겠습니다. 가령 $p$가 0.05보다 작아질 수록 $H_0$를 기각하거나 $H_1$를 수용할 이유가 커진다고 말하는 것은 적절하지 않겠죠? 기본적으로 $p$-value는 Fisher의 test에서 사용되는 개념이고, Fisher의 test of significance는 기각-수용이라는 의사결정을 목적으로 하지 않습니다. $p$는 그저 $H_0$가 data와 일치하지 않는 정도를 보여주는 것입니다. 이는 [1-1절]({% post_url 2024-05-22-p-val-1 %}#1-1-fishers-test-of-significance){:target="_blank"}에서도 이야기한 바 있습니다.  

## 4-7. H0는 언제나 거짓이 아닌가?
1. NHST에 가해지는 비판 중 대표적인 것 중 하나가 null hypothesis ($H_0$)가 사실인 경우는 보통 없다는 주장입니다. 
	1. Tukey는 "A와 B의 효과가 다른가"라는 질문에 "They are always different for some decimal place" ("소숫점 몇째 자리까지 보면 항상 다르겠지")라고 답하며 NHST를 비판하였습니다 ([Tukey, 1991](#62f187)).  
	2. Meehl은 적어도 soft psychology 분야에서 "... as I believe is generally recognized by statisticians today and by thoughtful social scientists, the null hypothesis, taken literally, is always false" 라며 $H_0$가 언제나 거짓이라고 설명합니다 ([Meehl, 1978](#be9d84)). 
	3. Cohen도 다음과 같이 null hypothesis가 언제나 거짓이라고 설명합니다 ([Cohen, 1990](#07cba5)): 
	> The null hypothesis, taken literally (and that's the only way you can take it in formal hypothesis testing), is *always* false in the real world. It can only be true in the bowels of a computer processor running a Monte Carlo study (and even then a stray electron may make it false). If it is false, even to a tiny degree, it must be the case that a large enough sample will produce a significant result and lead to its rejection. So if the null hypothesis is always false, what's the big deal about rejecting it?
	4. 즉, $H_0$가 언제나 거짓이라면 이를 기각하는 것이 의미가 없다는 것입니다.
2. 하지만 Tukey를 비롯한 학자들의 이러한 견해가 가설 검정에 관한 잘못된 이해에서 비롯하며, NHST가 의미없다는 비판이 유효하지 않다는 반박도 있습니다:
	1. Point null (e.g. $\theta = \theta_0$)을 사용하는 것은 현실의 문제에 적절한 근사를 제공하므로 유용합니다 ([Berger & Selke, 1987](#3cc52e)). Berger와 Selke는 실제로는 $H_0 : \vert \theta − \theta_0 \vert \le b$라는 가설을 사용하는 것이 타당하지만, 대개 $b$는 충분히 작으며 충분히 작은 $b$에 대해서는 $H_0 : \theta = \theta_0$ 로 근사될 수 있다는 결론을 내립니다. (**아직 직접 읽고 이해하지 못함. Berger&Selke와 Berger&Delampady 둘다 보기.**)
	2. 모집단 간 평균 차이가 아주 미미할 때 $H_0$ 를 기각하기 위해서는 sample size가 상당히 커야합니다. 가령 two-sided $t$-test ($\alpha = 0.05, \beta = 0.8$)에서 Cohen’s $d = 0.001$인 정도로 미미한 차이를 기각하기 위해서는 $n_1 + n_2 \approx 31,000,000$의 표본이 필요합니다. Sample size가 저렇게 크지 않은 대부분의 상황에서는 미미한 차이가 있어도 $H_0$ 가 기각되지 않으므로 $H_0$가 가설로 적절하다는 주장입니다. 
	
		주제에서 벗어나긴 하지만... sample size가 어떻게 계산되는지 잠깐 알아볼까요? $\sigma$가 알려져 있고 $\mu_1 - \mu_2 = \Delta$라 합시다. $\alpha = 0.05$이도록 하는 critical region $C$는 $1.96$입니다. $Z = \frac{(\bar{X_1}-\bar{X_2}-\Delta)}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}} \sim N(0, 1)$인 $Z$와 test statistic $T$에 대해, power는 다음과 같이 계산됩니다:$$\begin{align}power = \Pr(T > C \mid \mu_1 \ne \mu_2) &= \Pr\Biggr(\frac{\bar{X_1}-\bar{X_2}}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}} > 1.96\Biggl) \\&= \Pr\Biggr(\frac{\bar{X_1}-\bar{X_2} - \Delta}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}} > 1.96 - \frac{\Delta}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}}\Biggl) \\&= \Pr\Biggr(Z > 1.96 - \frac{\Delta}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}}\Biggl) \end{align}$$ 
		
		$\sigma_1=\sigma_2 = 1$, $\Delta = 0.001$이고 $n_1 = n_2 = n$인 경우, power는 $\Pr(Z>1.96 - \frac{0.001\sqrt{n}}{\sqrt{2}})$이고, 바로 이 power가 $80\%$이도록 하는 $n$을 찾으면 됩니다.
		```r
		C <- qnorm(0.025, lower.tail = FALSE)
		sd <- sqrt(2)
		power <- quote({ pnorm(C - 0.001 * sqrt(n) / sd, lower.tail = FALSE) }) # not evaluated

		n <- uniroot(function(n) eval(power) - 0.8, c(2 + 1e-10, 1e+09))$root # solve the equation

		n
		#> [1] 15697759
		```
		$n_1 + n_2 = 2n = 31,395,519$임을 확인할 수 있습니다.

	3. NHST는 sample을 통해 현실 세계에 있는 모집단에 관한 정보를 얻기 위해 사용하는 도구입니다. Lakens는 위의 반박들이 NHST를 통해 알고자 하는 '현실 세계 (real world)'가 무엇인지 놓치고 있다고 주장합니다 ([Lakens, 2014](#bee925)).
		- 현실 세계에서는 지금 이 순간에도 사람들이 죽고 태어나고 있습니다. 오늘 측정한 모집단의 parameter는 내일 측정한 모집단의 parameter와 분명 다를 것입니다. 
		- 하지만 NHST에서는 특정한 시점의 parameter가 정확히 어떤 값인지가 중요한 것이 아닙니다. NHST를 통해 우리는 현실 세계에 대한 **일반화되고 평균적인 진술**의 참거짓 판단에 *참고할만한* 자료를 얻고자 하기 때문이죠. 그러므로 $H_0: \theta = \theta_0$가 언제나 잘못되었다는 사실이 point null hypothesis가 NHST에서 쓰이지 못할 이유가 되지 않습니다.  



## Reference
- <a id="89420d"></a> Berger, J. O., & Delampady, M. (1987). Testing Precise Hypotheses. *Statistical Science, 2*(3), 317-335. [https://doi.org/10.1214/ss/1177013238](https://doi.org/10.1214/ss/1177013238){:target="_blank"}  
- <a id="3cc52e"></a> Berger, J. O., & Sellke, T. (1987). Testing a Point Null Hypothesis: The Irreconcilability of P Values and Evidence. *Journal of the American Statistical Association, 82*(397), 112-122. [https://doi.org/10.2307/2289131](https://doi.org/10.2307/2289131){:target="_blank"}  
- <a id="07cba5"></a> Cohen, J. (1990). Things I have learned (so far).*American Psychologist, 45*(12), 1304-1312. [https://doi.org/10.1037/0003-066X.45.12.1304](https://doi.org/10.1037/0003-066X.45.12.1304){:target="_blank"}  
- <a id="ca70e2"></a> Edgington, E. S. (1965). The assumption of homogeneity of variance for the "t" test and nonparametric tests. *Journal of Psychology, 59*, 177.  
- <a id="aa0559"></a> Goodman, S. N. (1999). Toward Evidence-Based Medical Statistics. 1: The P Value Fallacy. *Annals of Internal Medicine, 130*(12), 995-1004. [https://doi.org/10.7326/0003-4819-130-12-199906150-00008](https://doi.org/10.7326/0003-4819-130-12-199906150-00008){:target="_blank"}  
- <a id="9cd7a5"></a> Greenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., & Altman, D. G. (2016). Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations. *European Journal of Epidemiology, 31*(4), 337-350. [https://doi.org/10.1007/s10654-016-0149-3](https://doi.org/10.1007/s10654-016-0149-3){:target="_blank"}  
- <a id="bee925"></a> Lakens, D. (2014, June 12). The Null Is Always False (Except When It Is True). *The 20% Statistician*. [https://daniellakens.blogspot.com/2014/06/the-null-is-always-false-except-when-it.html](https://daniellakens.blogspot.com/2014/06/the-null-is-always-false-except-when-it.html){:target="_blank"}  
- <a id="83ef58"></a> Lakens, D. (2024). *Improving Your Statistical Inference* (1.4.5 ed.). [https://lakens.github.io/statistical_inferences](https://lakens.github.io/statistical_inferences){:target="_blank"} 
- <a id="a0c299"></a> Lavine, M. (2024). P-values don’t measure evidence. *Communications in Statistics - Theory and Methods, 53*(2), 718-726. https://doi.org/10.1080/03610926.2022.2091783 
- <a id="be9d84"></a> Meehl, P. E. (1978). Theoretical risks and tabular asterisks: Sir Karl, Sir Ronald, and the slow progress of soft psychology. *Journal of Consulting and Clinical Psychology, 46*(4), 806-834. [https://doi.org/10.1037/0022-006X.46.4.806](https://doi.org/10.1037/0022-006X.46.4.806){:target="_blank"}  
- <a id="5d12f0"></a> Miller, J. (2009). What is the probability of replicating a statistically significant effect? *Psychonomic Bulletin & Review, 16*(4), 617-640. [https://doi.org/10.3758/pbr.16.4.617](https://doi.org/10.3758/pbr.16.4.617){:target="_blank"}  
- <a id="62f187"></a> Tukey, J. W. (1991). The Philosophy of Multiple Comparisons. *Statistical Science, 6*(1), 100-116. [http://www.jstor.org/stable/2245714](http://www.jstor.org/stable/2245714){:target="_blank"}  

[^1]: Edgington의 연구를 사례로 들어, $p = 0.01 < 0.05 = \alpha$인 상황을 고려해 보자. (1) 만약 아무런 가정없이 $p = 0.01$이 나왔는데 $H_0: \mu_1 = \mu_2$를 기각하였다면, independent identically distributed(i.i.d) normal population에서 random sampling되지 않았을 수 있다고 반박할 수 있겠다. (2) 만약 i.i.d. normal population에서 random sampling되었다는 가정이 전제되었을 때 $H_0$를 기각하였다면, $\mu$에서 차이가 발생한 것이었을 수 있지만 $\sigma^2$에서 차이가 발생한 경우일 수도 있다. (3) 만약 i.i.d. normal, homoscedastic population에서 random sampling되었다는 가정이 전제된다면 그때야말로 $H_0: \mu_1 = \mu_2$에 관한 기각 여부를 다룰 수 있는 것이다. ([Edgington, 1965](#ca70e2))

[^2]: Evidence가 likelihood에 의해 정량될 수 있다는 주장에 대해, Greenland는 likelihood function이 evidence를 포착하는데 실패하며 likelihood가 evidence의 모든 측면을 아우르지도 않는다는 여러 연구를 제시하면서 statistical evidence에 대한 합의된 단일 정의는 없다고 본다 ([Greenland, 2023](#30bdb1)).
